# LLM Provider (choose one)
# Use OpenAI directly
OPENAI_API_KEY=your_openai_key_here

# OR use OpenRouter (supports multiple LLM providers: OpenAI, Anthropic, Google, etc.)
OPENROUTER_API_KEY=your_openrouter_key_here

# Required Services
TENSORLAKE_API_KEY=your_tensorlake_key_here
VOYAGE_API_KEY=your_voyage_key_here
ZEP_API_KEY=your_zep_key_here
FIRECRAWL_API_KEY=your_firecrawl_key_here

# Server Configuration
API_PORT=8003
FRONTEND_PORT=3003

# CORS Configuration (Required for production)
# Add your production frontend URLs here (comma-separated, no spaces needed)
# Example: CORS_ORIGINS=https://contextstack.apexneural.cloud,https://www.contextstack.apexneural.cloud
# CORS_ORIGINS=https://your-production-domain.com

# Optional Configuration
# QDRANT_DB_PATH=./qdrant_db  # Optional: Defaults to backend/qdrant_db automatically (works from any directory)
# DEBUG=true  # Optional: Enable debug logging to see CORS configuration on startup

# Get your API keys:
# - Tensorlake: https://tensorlake.ai/
# - Voyage AI: https://dashboard.voyageai.com/
# - Zep AI: https://www.getzep.com/
# - Firecrawl: https://www.firecrawl.dev/
# - OpenAI: https://openai.com
# - OpenRouter: https://openrouter.ai/
